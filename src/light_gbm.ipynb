{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "y = train[\"log_pSat_Pa\"]\n",
    "X = train.drop(columns=[\"log_pSat_Pa\"])\n",
    "\n",
    "non_numeric_cols = X.select_dtypes(include=['object']).columns\n",
    "X = pd.get_dummies(X, columns=non_numeric_cols, drop_first=True)\n",
    "test = pd.get_dummies(test, columns=non_numeric_cols, drop_first=True)\n",
    "\n",
    "X, test = X.align(test, join='left', axis=1)\n",
    "test = test.fillna(0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding out the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 925\n",
      "[LightGBM] [Info] Number of data points in the train set: 21309, number of used features: 28\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score -5.539761\n",
      "Top 15 most important features:\n",
      "             Feature  Importance\n",
      "7          NumOfConf         918\n",
      "0                 ID         746\n",
      "8      NumOfConfUsed         692\n",
      "1                 MW         487\n",
      "3             NumOfC         354\n",
      "6     NumHBondDonors         310\n",
      "2         NumOfAtoms         288\n",
      "11  hydroxyl (alkyl)         270\n",
      "13            ketone         240\n",
      "4             NumOfO         210\n",
      "R2 Score on Validation Set: 0.7432\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='rmse')\n",
    "\n",
    "feature_importance = lgb_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "most_important_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 most important features:\")\n",
    "print(most_important_df.head(10))\n",
    "\n",
    "y_pred = lgb_model.predict(X_val)\n",
    "print(f\"R2 Score on Validation Set: {r2_score(y_val, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding out the least important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least important features:\n",
      "                              Feature  Importance\n",
      "27         parentspecies_apin_toluene           0\n",
      "26  parentspecies_apin_decane_toluene           0\n",
      "29       parentspecies_decane_toluene           0\n",
      "19                  aromatic hydroxyl           0\n",
      "['parentspecies_apin_toluene', 'parentspecies_apin_decane_toluene', 'parentspecies_decane_toluene', 'aromatic hydroxyl']\n"
     ]
    }
   ],
   "source": [
    "least_important_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# Display least important features\n",
    "print(\"Least important features:\")\n",
    "print(least_important_df.head(4))\n",
    "\n",
    "least_important_names = list(least_important_df['Feature'].head(4))\n",
    "print(least_important_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding out the least important features, we can re-trained the model and change the values of some hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 923\n",
      "[LightGBM] [Info] Number of data points in the train set: 21309, number of used features: 27\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score -5.539761\n",
      "R2 Score on Re-Trained Validation Set: 0.7447\n"
     ]
    }
   ],
   "source": [
    "X_reduced = X.drop(columns=least_important_names)\n",
    "\n",
    "X_reduced, test = X_reduced.align(test, join='left', axis=1)\n",
    "test = test.fillna(0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_reduced, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=50,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='rmse')\n",
    "\n",
    "feature_importance = lgb_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "y_pred = lgb_model.predict(X_val)\n",
    "print(f\"R2 Score on Re-Trained Validation Set: {r2_score(y_val, y_pred):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the features with 0 importance and reducing them and lifting the num_leaves parameter from 31 to 50 and lowering n_estimators from 200 to 100, the R2 score went up to 0.7447, i.e. there is a rise of 0.0015. After playing around with other parameters, no improvements with the R2 score was found."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
